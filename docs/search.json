[
  {
    "objectID": "posts/Blog Post 2/index.html",
    "href": "posts/Blog Post 2/index.html",
    "title": "Blog Post 2 - Valentine’s Day Consumer Data",
    "section": "",
    "text": "Introduction\nThis is a dataset form the Tidy Tuesday Github about Valentine’s Day consumers. There are three datasets, historical_spending, gifts_age, and gifts_gender.\nhistorical_spending is data on the money spent on Valentine’s Day gifts from 2010 to 2022. Year is the year, PercentCelebrating is the percent of people celebrating, and all the other columns is the average amount of money spent by people on that item.\ngifts_age has data on how much money different age groups are spending on Valentine’s Day, and how much they spend on what items. Age is the age range, SpendingCelebrating is the percent of that group that is spending money on, or is celebrating, Valentines Day, the other columns are the average percent spending money on that item.\ngifts_gender is data on men’s vs womens’ spending on Valentine’s Day. The columns are the same as gifts_age, except the age column is replaces with gender.\nIll be making some plots to show a comparison between each datasets main focus (over time, between different age groups, and by gender) and examine how spending changes.\nData Source: https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-02-13/readme.md\n\nlibrary(tidyverse)\n\n\nhistorical_spending &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-02-13/historical_spending.csv')\ngifts_age &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-02-13/gifts_age.csv')\ngifts_gender &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-02-13/gifts_gender.csv')\n\n\nhistorical_spending\n\n# A tibble: 13 × 10\n    Year PercentCelebrating PerPerson Candy Flowers Jewelry GreetingCards\n   &lt;dbl&gt;              &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;\n 1  2010                 60      103    8.6    12.3    21.5          5.91\n 2  2011                 58      116.  10.8    12.6    26.2          8.09\n 3  2012                 59      126.  10.8    13.5    29.6          6.93\n 4  2013                 60      131.  11.6    13.5    30.9          8.32\n 5  2014                 54      134.  10.8    15      30.6          7.97\n 6  2015                 55      142.  12.7    15.7    36.3          7.87\n 7  2016                 55      147.  13.1    14.8    33.1          8.52\n 8  2017                 54      137.  12.7    14.6    32.3          7.36\n 9  2018                 55      144.  13.1    14.8    34.1          6.55\n10  2019                 51      162.  14.1    15.1    30.3          7.31\n11  2020                 55      196.  17.3    16.5    41.6          9.01\n12  2021                 52      165.  15.3    15.4    30.7          8.48\n13  2022                 53      175.  15.9    16.7    45.8          7.47\n# ℹ 3 more variables: EveningOut &lt;dbl&gt;, Clothing &lt;dbl&gt;, GiftCards &lt;dbl&gt;\n\ngifts_age\n\n# A tibble: 6 × 9\n  Age   SpendingCelebrating Candy Flowers Jewelry GreetingCards EveningOut\n  &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 18-24                  51    70      50      33            33         41\n2 25-34                  40    62      44      34            33         37\n3 35-44                  31    58      41      29            42         30\n4 45-54                  19    60      37      20            42         31\n5 55-64                  18    50      32      13            43         29\n6 65+                    13    42      25       8            44         24\n# ℹ 2 more variables: Clothing &lt;dbl&gt;, GiftCards &lt;dbl&gt;\n\ngifts_gender\n\n# A tibble: 2 × 9\n  Gender SpendingCelebrating Candy Flowers Jewelry GreetingCards EveningOut\n  &lt;chr&gt;                &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 Men                     27    52      56      30            37         33\n2 Women                   27    59      19      14            43         29\n# ℹ 2 more variables: Clothing &lt;dbl&gt;, GiftCards &lt;dbl&gt;\n\n\n\n\nPrimary Visualizations\nHere are three different graphs to show the change in the percentage of people celebrating Valentine’s Day over the years (2010 - 2022). Each shows that although the percentage fluctuates somewhat, it generally has been decreasing.\n\nggplot(historical_spending, aes(x = Year, y = PercentCelebrating)) +\n  geom_col(fill = \"blue\") +\n  labs(title = \"Percentage of People Celebrating Valentine's Day\",\n       subtitle = \"From 2010 to 2022\",\n       x = \"Year\",\n       y = \"Percentage Celebrating\") +\n  theme_minimal()\n\n\n\n\n\nggplot(historical_spending, aes(x = Year, y = PercentCelebrating)) +\n  geom_line(color = \"blue\", size = 1.5) + \n  ylim(48, 63) + \n  labs(title = \"Percentage of People Celebrating Valentine's Day\",\n       subtitle = \"From 2010 to 2022\",\n       x = \"Year\",\n       y = \"Percentage Celebrating\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThis scatter plot and smoother best represent the change in the percentage of those who are celebrating.\n\nggplot(historical_spending, aes(x = as.Date(historical_spending$Year), y = PercentCelebrating)) +\n  geom_point(color = \"blue\") +\n  geom_smooth(color = \"skyblue\") +\n  labs(title = \"Percentage of People Celebrating Valentine's Day\",\n       subtitle = \"From 2010 to 2022\",\n       x = \"Year\",\n       y = \"Percentage Celebrating\") +\n  theme_minimal()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nhistorical_spending_long &lt;- historical_spending |&gt;\n  select(-PerPerson, -PercentCelebrating) |&gt;\n  pivot_longer(cols = -Year,\n             names_to = \"Category\",\n             values_to = \"Spending\")\n\nThis is a graph of the average amount of money people spent on each of the gifts in the data set over the years. One interesting thing about this graph is the sharp drop in “EveningOut” from 2020 to 2021, of course, when Covid was keeping everyone in their homes! It seems for some reason it also affected jewelry purchases. Considering that outlier of a year, it’s also interesting to see that while the percentage of people celebrating is dropping (graphs above), the amount that those who are celebrating spent is increasing over the years.\n\nggplot(historical_spending_long, aes(x = Year, y = Spending, color = Category)) +\n  geom_line(size = 1.5) +\n  labs(title = \"Average Amount Spent on Gifts Over the Years\",\n       subtitle = \"From 2010 to 2022\",\n       x = \"Year\",\n       y = \"Average Amount of Money Spent\") +\n  theme_minimal()\n\n\n\n\n\ngifts_gender_long &lt;- gifts_gender |&gt; \n  select(-SpendingCelebrating) |&gt;\n  pivot_longer(cols = -Gender,\n               names_to = \"gift\",\n               values_to = \"spent\")\n\nThis is a plot of the spending habits of men vs. women. The y-axis represents the proportion of men/women who said that they did purchase that gift for their partner on Valentine’s Day, NOT the average amount spent on those items.\n\nggplot(gifts_gender_long, aes(x = gift, y = spent, fill = Gender)) +\n  geom_col(position = position_dodge()) +\n  labs(title = \"Gift Purchasing Habits, Male vs. Female\",\n       x = \"Gift\",\n       y = \"Proportion\",\n       fill = \"Gender\") +\n  scale_fill_manual(values = c(\"skyblue\", \"pink\")) + \n  theme_minimal()\n\n\n\n\n\n\nConclusion and Wrap-Up\nThe data I selected might be a bit limited in showing more in-depth changes in gender and age from year to year, but still has interesting data on the overall spending habits of people. It could have been interesting to see if there were any changes in what different age groups or genders were buying from 2010 to 2022. I think something I could have included was some sort of comparison between 2020-2021 and the average of the other years or something, after realizing there was a visible effect of Covid in the gift-giving graph.\n\n\nConnection to Class Ideas\nI think I’ve done a good job of selecting the correct types of graphs for each topic I’ve chosen. I think I would like to get better at visualizing linear models as I didn’t include anything related to that because I was confused and did not do it right when I tried."
  },
  {
    "objectID": "posts/Blog Post 3/index.html",
    "href": "posts/Blog Post 3/index.html",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "",
    "text": "This dataset has information on Mr. Trash Wheel, a semi-autonomous trash interceptor, it is placed in a river that the ocean flows into and removes trash from the water. Using solar power and hydro power generated by the river, it also sustainably powers homes. I’ll be examining how much power Mr. Trash Wheel has generated over the years, how much of each type of trash is picked up and if it changes over time, and how much is collected in total. This data is from the tidy Tuesday github for March 5th. There’s 993 entries, each representing one emptying of the dumpster, and 16 variables. ID, Name, Dumpster, Month, Year, Date, Weight, Volume, HomesPowered, and 7 variables for specific types of trash. ID and Name are the nickname and name given to Mr. Trash Wheel that have changed occasionally over the years. Dumpster is the dumpster number. Month, Year, and Date are the month, year, and date that the data was collected. Weight and Volume are the weight in tons and volume in cubic yards, of trash collected. The other variables for types of trash are: PlasticBottles, Polystyrene, CigaretteButts, GlassBottles, PlasticBags, Wrappers, and SportsBalls.\nSource: https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-03-05/readme.md\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(modelr)\n\n\ntrashwheel &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-03-05/trashwheel.csv')\n\ntrashwheel[is.na(trashwheel)] &lt;- 0"
  },
  {
    "objectID": "posts/Blog Post 3/index.html#the-total-weight-of-trash-collected-each-year.",
    "href": "posts/Blog Post 3/index.html#the-total-weight-of-trash-collected-each-year.",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "The total weight of trash collected each year.",
    "text": "The total weight of trash collected each year.\n\nggplot(trashwheel, aes(x = Year, y = Weight)) +\n  geom_col(fill = \"orchid3\", color = \"orchid4\") +\n  labs(title = \"Total Tons of Trash Collected Each Year\",\n       x = \"Year\",\n       y = \"Tons of Trash Collected\") +\n  theme_minimal()\n\n\n\n\n\nweight_df &lt;- trashwheel |&gt; group_by(Year) |&gt; summarise(Weight = sum(Weight))\n\nggplot(weight_df, aes(x = Year, y = Weight)) +\n  geom_col(fill = \"skyblue3\", color = \"skyblue4\") +\n  labs(title = \"Total Tons of Trash Collected Each Year\",\n       x = \"Year\",\n       y = \"Tons of Trash Collected\") +\n  theme_minimal()\n\n\n\n\nHere is two versions of a bar-plot to how how many tons of trash were intercepted each year, 2014 to 2023. It is clear that the weight of trash collected is growing. This could mean that Mr. Trash Wheel is working more efficiently, that the amount of trash in the ocean has increased, or (very likely) both. Looking at the orchid plot, each box that makes up the columns is one instance of emptying of the dumpster, and while it isn’t clear how many entries exactly are in each year, it is clear that the number of times the dumpster was emptied has increased each year."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#the-weight-of-trash-in-each-entry-over-the-years.",
    "href": "posts/Blog Post 3/index.html#the-weight-of-trash-in-each-entry-over-the-years.",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "The weight of trash in each entry over the years.",
    "text": "The weight of trash in each entry over the years.\n\nggplot(trashwheel, aes(x = Year, y = Weight)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\n\n\nThis plot shows all each time the dumpster was empties, how many tons of trash were collected in that dumpster, and the trend of the average weight of trash in dumpsters when they are emptied. The above plots show that the total tons of trash collected each year is increasing, and this plot shows that the average tons of trash collected in each dumpster before emptying is decreasing. This is likely because we know the number of times the dumpster is emptied each year has greatly increased, it actually seems impressive how little the weight collected by dumpsters has changed since 2014 knowing in 2023 they were empties more then 3 times as often."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#how-many-homes-are-predicted-to-be-powered-based-on-volume-and-weight-of-trash.",
    "href": "posts/Blog Post 3/index.html#how-many-homes-are-predicted-to-be-powered-based-on-volume-and-weight-of-trash.",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "How many homes are predicted to be powered based on volume and weight of trash.",
    "text": "How many homes are predicted to be powered based on volume and weight of trash.\n\ntrash_mod &lt;- lm(HomesPowered ~ Weight + Weight:Volume + Volume, \n                data = trashwheel)\n\ngrid &lt;- trashwheel |&gt;\n  data_grid(\n    Weight = seq_range(Weight, n = 10),\n    Volume = seq_range(Volume, n = 4))\n\ntrash_aug &lt;- augment(trash_mod, newdata = grid,\n                   interval = \"confidence\")\n\n\nggplot(trash_aug, aes(x = Weight, y = .fitted)) +\n  geom_point(data = trashwheel, aes(y = HomesPowered), alpha = 0.2) +\n  geom_ribbon(aes(ymin = .lower, ymax = .upper, fill = as.factor(Volume)), alpha = 0.3) +\n  scale_fill_viridis_d() +\n  theme_minimal() +\n  labs(color = \"Volume\", y = \"Homes Powered\")\n\n\n\n\nThis graph shows the predicted amount of homes powered based on the weight and volume of trash collected. More tons of trash means more power, but, 5 cubic yards of heavy trash is more efficient then 20 cubic yards of heavy trash. This may be because Mr. Trash Wheel used hydro power from the river to generate power, so trash density might effect how much power it creates."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#average-of-trash-popularity-over-time.",
    "href": "posts/Blog Post 3/index.html#average-of-trash-popularity-over-time.",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "Average of trash popularity over time.",
    "text": "Average of trash popularity over time.\n\ntrash_long &lt;- trashwheel |&gt; select(Year, PlasticBottles, Polystyrene, CigaretteButts,\n                     GlassBottles, PlasticBags, Wrappers, SportsBalls) |&gt;\n  pivot_longer(cols = c(PlasticBottles, Polystyrene, CigaretteButts, \n                        GlassBottles, PlasticBags, Wrappers, SportsBalls),\n               names_to = \"type\", values_to = \"amount\") |&gt;\n  group_by(Year, type) |&gt;\n  summarise(amount = mean(amount))\n\n\nggplot(trash_long, aes(x = Year, y = amount, color = type)) +\n  geom_line(size = 0.75) +\n  scale_color_viridis_d()\n\n\n\n\nHere is a plot that shows how common each of the 7 types of trash are when emptying the dumpster. Cigarettes clearly were the most common, and still in 2023 are the most common. When Mr. Trash Wheel was first installed cigarette it was collecting hundreds of thousands of cigarette butts each year (almost a million the first year), but there has been a sharp decline.\n\nAverage of trash popularity over time (Without Cigs).\n\nno_cig &lt;- trashwheel |&gt; select(Year, PlasticBottles, Polystyrene,\n                     GlassBottles, PlasticBags, Wrappers, SportsBalls) |&gt;\n  pivot_longer(cols = c(PlasticBottles, Polystyrene, \n                        GlassBottles, PlasticBags, Wrappers, SportsBalls),\n               names_to = \"type\", values_to = \"Amount\") |&gt;\n  group_by(Year, type) |&gt;\n  summarise(Amount = mean(Amount))\n\n\nggplot(no_cig, aes(x = Year, y = Amount, color = type)) +\n  geom_line(size = 1.5) +\n  scale_color_viridis_d()\n\n\n\n\nMaking this plot with out cigarette butts, we can more clearly see the popularity of the other 6 trash types. Sports balls and glass bottles are least common. This isn’t surprising to me for sports balls but, I assumes glass bottles would be higher. There also seems to be a spike in 2017, and a lull in 2021. 2021 might have to do with covid, Mr. Trash Wheel relies on trash flowing in from the ocean which might take time and the lock down might have caused people to not be able to litter as much, but the spike in 2017 is interesting and I’m not sure what would have caused that."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#number-of-homes-powered",
    "href": "posts/Blog Post 3/index.html#number-of-homes-powered",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "Number of homes powered",
    "text": "Number of homes powered\n\nggplot(trashwheel, aes(x = Year, y = HomesPowered)) +\n  geom_point() +\n  geom_smooth(color = \"red\") + \n  labs(title = \"Homes Powered Over the Years\",\n       x = \"Year\",\n       y = \"Homes Powered\") +\n  theme_minimal()\n\n\n\n\nThis graph focuses on the number of homes powered over the years. The other graph looked at how many homes would be powered based on weight and volume of trash, this graph shows us just how the number of homes powered has changed. Each point is one emptying of the dumpster, and how many homes were powered since the last entry. If we compare this graph and the one above, we see the effects of the spike in trash in 2017, with a bump in the number of homes powered. After that it seems the number of homes powered hasn’t changed much."
  },
  {
    "objectID": "posts/Blog Post 3/index.html#trash-by-month.",
    "href": "posts/Blog Post 3/index.html#trash-by-month.",
    "title": "Blog Post 3 - Mr. Trash Wheel Data",
    "section": "Trash by month.",
    "text": "Trash by month.\n\nmonths_df &lt;- trashwheel |&gt;\n  filter(!is.na(Month)) |&gt; \n  group_by(Month) |&gt;\n  summarise(avg_weight = mean(Weight), sum_weight = sum(Weight)) |&gt;\n  arrange(Month) |&gt;\n  mutate(Month = fct_reorder(Month, avg_weight))\n\nmay_july &lt;- months_df |&gt; filter(Month == c(\"May\", \"July\"))\n\n\nggplot(months_df, aes(x = Month, y = avg_weight)) +\n  geom_segment(aes(xend = Month, yend = 0, color = Month)) +  \n  geom_point(aes(color = Month), size = 1.5) +  \n  scale_color_manual(values = c(\"May\" = \"violet\", \"July\" = \"yellow3\", \"June\" = \"red2\", \n                                \"April\" = \"red2\", \"January\" = \"limegreen\")) + \n  labs(title = \"Average Weight of Trash Collected in Each Month\",\n       subtitle = \"From 2014 - 2023\",\n       x = \"Month\",\n       y = \"Average Weight (in Tons)\") +\n  coord_flip() +\n  theme_minimal() +\n  guides(color = \"none\")\n\n\n\n\n\nggplot(months_df |&gt; arrange(Month) |&gt; mutate(Month = fct_reorder(Month, sum_weight)), \n       aes(x = Month, y = sum_weight)) +\n  geom_segment(aes(xend = Month, yend = 0, color = Month)) +  \n  geom_point(aes(color = Month), size = 1.5) +  \n  scale_color_manual(values = c(\"May\" = \"violet\", \"July\" = \"yellow3\", \"June\" = \"red2\", \n                                \"April\" = \"red2\", \"January\" = \"limegreen\")) + \n  labs(title = \"Total Weight of Trash Collected in Each Month\",\n       subtitle = \"From 2014 - 2023\",\n       x = \"Month\",\n       y = \"Total Weight (in Tons)\") +\n  coord_flip() +\n  theme_minimal() +\n  guides(color = \"none\")\n\n\n\n\nThese two plots show the months by average tons of trash collected and total tons of trash collected. I’ve highlighted some of the months. July has the most total tons of trash but is 4th in average tons, May has the highest average, but is 6th in total. June and April are consistently the highest when looking at both graphs, and January is the lowest in both. It seems January is a very clean month."
  },
  {
    "objectID": "posts/Blog Post 1/index.html",
    "href": "posts/Blog Post 1/index.html",
    "title": "Blog Post 1 - Groundhogs Day Data",
    "section": "",
    "text": "The datasets I will be looking at contain data on groundhogs day groundhogs and their predictions of whether winter will come or not. In the predictions df there is 1400+ entries of id (groundhog id), year, shadow (T or F), and details. Details is any extra writen info that could add context to the sighting of the shadow. The groudhogs df has 75 entries with the groundhogs ids, information on the groundhogs, and information on the city/region where the groundhog is “from”. I’ll be making some plots to look compare the groundhogs and their predictions. This data is from the January 30th enrty of the tidy-tuesday github page.\n\nlibrary(tidyverse)\n\n\ngroundhogs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-30/groundhogs.csv')\npredictions &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-30/predictions.csv')\n\n\ngroundhogs\n\n# A tibble: 75 × 17\n      id slug     shortname name  city  region country latitude longitude source\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n 1     1 punxsut… Phil      Punx… Punx… Penns… USA         40.9     -79.0 \"http…\n 2     2 octorar… Orphie    Octo… Quar… Penns… USA         39.8     -76.1 \"http…\n 3     3 wiarton… Willie    Wiar… Wiar… Ontar… Canada      44.7     -81.1 \"http…\n 4     4 jimmy-t… Jimmy     Jimm… Sun … Wisco… USA         43.2     -89.2 \"http…\n 5     5 concord… Charlie   Conc… Athe… West … USA         37.4     -81.0 \"http…\n 6     6 buckeye… Chuck     Buck… Mari… Ohio   USA         40.6     -83.1 \"http…\n 7     7 general… Beau      Gene… Jack… Georg… USA         33.2     -83.9 \"http…\n 8     8 french-… Freddie   Fren… Upsh… West … USA         38.9     -80.3 \"http…\n 9     9 gertie-… Gertie    Gert… Hann… Illin… USA         40.7     -89.7 \"http…\n10    10 dunkirk… Dave      Dunk… Dunk… New Y… USA         42.5     -79.4 \"http…\n# ℹ 65 more rows\n# ℹ 7 more variables: current_prediction &lt;chr&gt;, is_groundhog &lt;lgl&gt;, type &lt;chr&gt;,\n#   active &lt;lgl&gt;, description &lt;chr&gt;, image &lt;chr&gt;, predictions_count &lt;dbl&gt;\n\npredictions\n\n# A tibble: 1,462 × 4\n      id  year shadow details                                                   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  &lt;chr&gt;                                                     \n 1     1  1886 NA     Groundhog Day first recognized in Punxsutawney by Weather…\n 2     1  1887 TRUE   First Official trek to Gobbler’s Knob. Saw Shadow.        \n 3     1  1888 TRUE   Saw Shadow.                                               \n 4     1  1889 NA     No Record.                                                \n 5     1  1890 FALSE  No Shadow.                                                \n 6     1  1891 NA     No Record.                                                \n 7     1  1892 NA     No Record.                                                \n 8     1  1893 NA     No Record.                                                \n 9     1  1894 NA     No Record.                                                \n10     1  1895 NA     No Record.                                                \n# ℹ 1,452 more rows"
  },
  {
    "objectID": "posts/Blog Post 1/index.html#groundhogs-per-region",
    "href": "posts/Blog Post 1/index.html#groundhogs-per-region",
    "title": "Blog Post 1 - Groundhogs Day Data",
    "section": "Groundhogs per Region",
    "text": "Groundhogs per Region\n\nper_region_df &lt;- groundhogs|&gt;\n  group_by(region)|&gt;\n  summarise(n_hogs = n()) |&gt;\n  arrange(desc(n_hogs)) |&gt;\n  mutate(region = fct_reorder(region, n_hogs))\n\n\nggplot(data = per_region_df, aes(x = region, y = n_hogs)) +\n  geom_segment(aes(xend = region, yend = 0)) +\n  geom_point() + \n  theme_minimal() +\n  coord_flip() +\n  labs(title = \"Number of Groundhogs per Region\",\n       x = \"Region\",\n       y = \"Number of Groundhogs\")\n\n\n\n\nA graph of how many groundhogs each region has. Each entry in groundhogs is a unique groundhog, so this counts the number of times each region is entered. The Pennsylvania region has the most ground hogs by almost double the second most."
  },
  {
    "objectID": "posts/Blog Post 1/index.html#different-groundhogs",
    "href": "posts/Blog Post 1/index.html#different-groundhogs",
    "title": "Blog Post 1 - Groundhogs Day Data",
    "section": "Different Groundhogs",
    "text": "Different Groundhogs\n\ntype_plot &lt;- groundhogs |&gt;\n  group_by(type) |&gt;\n  summarize(count = n()) |&gt;\n  mutate(type = if_else(count == 1, true = \"Other\", false = type)) |&gt;\n  group_by(type) |&gt;\n  summarize(count = sum(count)) |&gt;\n  arrange(desc(count)) |&gt;\n  mutate(type = fct_reorder(type, count))\n\n\npie(type_plot$count, labels = type_plot$type, main = \"Different Groundhogs\")\n\n\n\n\nThis pie chart shows some of the other “animals” that have been used in place of real groundhogs, and how common the alternatives are."
  },
  {
    "objectID": "posts/Blog Post 1/index.html#shadows-seen-vs.-not-seen",
    "href": "posts/Blog Post 1/index.html#shadows-seen-vs.-not-seen",
    "title": "Blog Post 1 - Groundhogs Day Data",
    "section": "Shadows Seen vs. Not Seen",
    "text": "Shadows Seen vs. Not Seen\n\npredictions_noNA_df &lt;- predictions |&gt;\n  filter(!is.na(shadow))\n\n\nggplot(data = predictions_noNA_df, aes(x = shadow)) +\n  geom_bar() +\n  geom_text(stat = \"count\", aes(label = after_stat(count)), vjust = -0.5) + # AI*\n  labs(title = \"Total Shadows Seen (True) vs. Not Seen (False)\",\n       x = \"\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nThis is a simple plot tallying the number of times a groundhog saw it’s shadow, vs time a groundhog didn’t see it’s shadow.\n\nInto chatGPT: “In this plot put the number of each bar on the bar: (My code for the plot minus the geom_text line)”"
  },
  {
    "objectID": "posts/Blog Post 1/index.html#proportion-of-shadows-seen-vs.-not-seen",
    "href": "posts/Blog Post 1/index.html#proportion-of-shadows-seen-vs.-not-seen",
    "title": "Blog Post 1 - Groundhogs Day Data",
    "section": "Proportion of Shadows Seen vs. Not Seen",
    "text": "Proportion of Shadows Seen vs. Not Seen\n\nshadow_prop &lt;- predictions_noNA_df |&gt;\n  group_by(year, shadow) |&gt;\n  summarise(n_predictions = n()) |&gt;\n  filter(n_predictions &gt; 1) |&gt;\n  ungroup() |&gt;\n  arrange(desc(year)) |&gt;\n  pivot_wider(names_from = shadow, values_from = n_predictions) \n\nshadow_prop[is.na(shadow_prop)] &lt;- 0 # AI*\n\nshadow_prop &lt;- shadow_prop |&gt;\n  mutate(n = `FALSE` + `TRUE`) |&gt;\n  filter(n &gt;= 10) |&gt;\n  mutate(samp_prop = `TRUE` / n,\n         se = sqrt(samp_prop * (1 - samp_prop) / n),\n         lb = samp_prop - se,\n         ub = samp_prop + se)\n\n\nInto chatGPT: “Give code in r to re-write an NA input to 0.”\n\n\nggplot(data = shadow_prop, aes(x = year, y = samp_prop)) +\n  geom_errorbar(aes(ymin = lb, ymax = ub)) +\n  geom_point() +\n  labs(title = \"Proportion of Shadows Seen vs. Not Seen\",\n       subtitle = \"(For years with over 10 observations by groundhogs)\",\n       x = \"Year\",\n       y = \"Proportion\") +\n  theme_minimal()\n\n\n\n\nThis plot shows the proportion of seen vs not seen shadows for years where 10 or more groundhogs observed their shadow. It seems that the groundhogs have started to disagree more in recent years but the standard deviation is getting smaller, this is probably because more groundhogs observe in recent years then early in the 90s and 2000s."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DATA334Blog",
    "section": "",
    "text": "Blog Post 3 - Mr. Trash Wheel Data\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nJeffrey Merselis\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2 - Valentine’s Day Consumer Data\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nJeffrey Merselis\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 1 - Groundhogs Day Data\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nJeffrey Merselis\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]